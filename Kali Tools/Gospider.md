
gospider -s [http://vulnnet.thm](http://vulnnet.thm) -c 10 -d 0 -w -t 10 â€” robots -a -r -v

## ðŸ“š Breakdown of Flags and Options:

|**Option**|**Meaning**|
|---|---|
|`-s http://vulnnet.thm`|**Start URL** â€“ The target domain to spider.|
|`-c 10`|**Concurrency** â€“ Run 10 threads to crawl URLs in parallel (speeds up scanning).|
|`-d 0`|**Max Depth** â€“ Crawl depth of 0, which means **only the given URL** is crawled (no sub-pages).|
|`-w`|**Enable Wordlist Output** â€“ Extract words and paths found in the HTML/JS and output them (useful for fuzzing).|
|`-t 10`|**Threads per site** â€“ Use 10 threads for each host/domain.|
|`--robots`|**Check and follow `robots.txt`** â€“ Tries to find and parse `/robots.txt` (can reveal hidden or restricted paths).|
|`-a`|**Include subdomains** â€“ Crawl subdomains found in the page (like `admin.vulnnet.thm`, etc).|
|`-r`|**Follow redirects** â€“ Follows HTTP 3xx redirects while crawling.|
|`-v`|**Verbose output** â€“ Print detailed logs of what GoSpider is doing.|


